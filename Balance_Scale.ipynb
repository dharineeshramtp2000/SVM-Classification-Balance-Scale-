{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Balance Scale.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/ZV9+ebD25HrxLSEkvAax",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dharineeshramtp2000/SVM-Classification-Balance-Scale-/blob/master/Balance_Scale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmeaUi3cXjJ6",
        "colab_type": "text"
      },
      "source": [
        "Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0gG7dpoXchH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwp1EEG2XqUH",
        "colab_type": "text"
      },
      "source": [
        "Importing the Dataset. Here we use the dataset from [ML Data](https://www.mldata.io/datasets/).\n",
        "![](https://cdn3.iconfinder.com/data/icons/market-and-economic/48/69-512.png)\n",
        "---\n",
        "\n",
        "Here we predict the class on which way the scale tips.\n",
        "**Values: L for left tip, B for balance, R for right tip**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tifsPeCMYo2u",
        "colab_type": "code",
        "outputId": "5f5ffa9d-e446-444c-f071-bc6552e4c232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "Dataset = pd.read_csv(\"balance_scale_weka_dataset.csv\")\n",
        "X = Dataset.iloc[:,:-1]\n",
        "y = Dataset.iloc[:,-1]\n",
        "Dataset.describe()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>left_weight</th>\n",
              "      <th>left_distance</th>\n",
              "      <th>right_weight</th>\n",
              "      <th>right_distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>625.000000</td>\n",
              "      <td>625.000000</td>\n",
              "      <td>625.000000</td>\n",
              "      <td>625.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.415346</td>\n",
              "      <td>1.415346</td>\n",
              "      <td>1.415346</td>\n",
              "      <td>1.415346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       left_weight  left_distance  right_weight  right_distance\n",
              "count   625.000000     625.000000    625.000000      625.000000\n",
              "mean      3.000000       3.000000      3.000000        3.000000\n",
              "std       1.415346       1.415346      1.415346        1.415346\n",
              "min       1.000000       1.000000      1.000000        1.000000\n",
              "25%       2.000000       2.000000      2.000000        2.000000\n",
              "50%       3.000000       3.000000      3.000000        3.000000\n",
              "75%       4.000000       4.000000      4.000000        4.000000\n",
              "max       5.000000       5.000000      5.000000        5.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbg5jOhBYx2V",
        "colab_type": "text"
      },
      "source": [
        "Now lets feature scale our independent variables from our famous [scikit](https://scikit-learn.org/stable/) library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Widc4BbzZNvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X = sc_X.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2CaoxRcZeMd",
        "colab_type": "text"
      },
      "source": [
        "Splitting the dataset into training and testing and performing a good shuffle of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP83grDqZlOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test, y_train, y_test = train_test_split(X, y , test_size = 0.3, random_state=0, shuffle =True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E82SIY2PZmNj",
        "colab_type": "text"
      },
      "source": [
        "Now lets define our SVM Classification model.\n",
        "We use the Gaussian Kernel which is most commonly preferred.\n",
        "Apart from that we define the constant C so that the hyperplane best fits for our train and test data.\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*c_JJszZ8GlnQ7kx88Z2TeA.png)\n",
        "\n",
        "Feel free to use the [Documnetaton for Support Vector Classification](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9bLh52NbAxk",
        "colab_type": "code",
        "outputId": "8ad66807-5ec6-4af3-cb77-804df9b4f547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(C = 10.0, kernel = 'rbf',decision_function_shape='onr')\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='onr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2j8E0L4b78d",
        "colab_type": "text"
      },
      "source": [
        "Now lets predict with our test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fMBI0Utb_rW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1xGFcQIcDJv",
        "colab_type": "text"
      },
      "source": [
        "Its time for evaluating our model.\n",
        "\n",
        "![](https://www.thinkebiz.net/wp-content/uploads/2018/01/74228032_s.jpg)\n",
        "\n",
        "---\n",
        "Lets first predict how our model is fitting for our training set\n",
        "We use the famous\n",
        "1.   f1 score\n",
        "2.   accuracy \n",
        "to evaluate the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEjsrO7ycCIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AodntoNGc62e",
        "colab_type": "code",
        "outputId": "67c513ca-6ded-49df-bca6-dbe8c98b4799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "acc_train = accuracy_score(y_train, classifier.predict(X_train))\n",
        "f1_train = f1_score(y_train, classifier.predict(X_train), average= 'weighted')\n",
        "\n",
        "print(\"Traing set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_train)\n",
        "print(\"F1 SCORE ---------------------->\",f1_train)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traing set results\n",
            "ACCURACY ----------------------> 0.9794050343249427\n",
            "F1 SCORE ----------------------> 0.9797582645377477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGihP6W9d3-E",
        "colab_type": "text"
      },
      "source": [
        "Now lets see how well is our model. So now lets evaluate with our test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAjgDCMbeCql",
        "colab_type": "code",
        "outputId": "a3a30c24-b919-4bde-a7d2-1cd5aec1e8e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "acc_test = accuracy_score(y_test, y_pred)\n",
        "f1_test = f1_score(y_test, y_pred, average= 'weighted')\n",
        "\n",
        "print(\"Test set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_test)\n",
        "print(\"F1 SCORE ---------------------->\",f1_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set results\n",
            "ACCURACY ----------------------> 0.9521276595744681\n",
            "F1 SCORE ----------------------> 0.9533721397029304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey2cFvHYehTh",
        "colab_type": "text"
      },
      "source": [
        "Now lets have our famous Confusion Matrix to visually understand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3MWd1w8etjW",
        "colab_type": "code",
        "outputId": "76d5828d-0c7d-49cc-f080-3aa37b010bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10  0  1]\n",
            " [ 2 93  1]\n",
            " [ 2  3 76]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQxBHanoex-e",
        "colab_type": "text"
      },
      "source": [
        "Our model has worked well with our test set too.\n",
        "The **accuaracy** and **f1 score** for both test and training set is good.\n",
        "Its always to put a question and ask to ourselves that is this the best model?\n",
        "\n",
        "---\n",
        "\n",
        "Obvisouly not!\n",
        "We can still achive our accuracy by changing our models, changing the independent variables, change the metrics and so on.\n",
        "Its great that we have successfully implemented SVM classification with our Balacne Scale Dataset.\n"
      ]
    }
  ]
}